{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37be7d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install poutyne    # Installing the Poutyne library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1c5c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install segmentation-models-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f499377",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "import segmentation_models_pytorch as smp\n",
    "import torchmetrics\n",
    "from poutyne import Model, ModelCheckpoint, CSVLogger, set_seeds\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def replace_tensor_value_(tensor, a, b):\n",
    "    tensor[tensor == a] = b\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def plot_images(images, num_per_row=8, title=None):\n",
    "    num_rows = int(math.ceil(len(images) / num_per_row))\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows, num_per_row, dpi=150)\n",
    "    fig.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "    for image, ax in zip(images, axes.flat):\n",
    "        ax.imshow(image)\n",
    "        ax.axis('off')\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "# Color palette for segmentation masks\n",
    "PALETTE = np.array(\n",
    "    [\n",
    "        [0, 0, 0],\n",
    "        [128, 0, 0],\n",
    "        [0, 128, 0],\n",
    "        [128, 128, 0],\n",
    "        [0, 0, 128],\n",
    "        [128, 0, 128],\n",
    "        [0, 128, 128],\n",
    "        [128, 128, 128],\n",
    "        [64, 0, 0],\n",
    "        [192, 0, 0],\n",
    "        [64, 128, 0],\n",
    "        [192, 128, 0],\n",
    "        [64, 0, 128],\n",
    "        [192, 0, 128],\n",
    "        [64, 128, 128],\n",
    "        [192, 128, 128],\n",
    "        [0, 64, 0],\n",
    "        [128, 64, 0],\n",
    "        [0, 192, 0],\n",
    "        [128, 192, 0],\n",
    "        [0, 64, 128],\n",
    "    ]\n",
    "    + [[0, 0, 0] for i in range(256 - 22)]\n",
    "    + [[255, 255, 255]],\n",
    "    dtype=np.uint8,\n",
    ")\n",
    "\n",
    "\n",
    "def array1d_to_pil_image(array):\n",
    "    pil_out = Image.fromarray(array.astype(np.uint8), mode='P')\n",
    "    pil_out.putpalette(PALETTE)\n",
    "    return pil_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4018c5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0005\n",
    "batch_size = 32\n",
    "image_size = 224\n",
    "num_epochs = 70\n",
    "imagenet_mean = [0.485, 0.456, 0.406]  # mean of the imagenet dataset for normalizing\n",
    "imagenet_std = [0.229, 0.224, 0.225]  # std of the imagenet dataset for normalizing\n",
    "set_seeds(43)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('The current processor is ...', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c6fcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_resize = transforms.Resize((224, 224))\n",
    "input_transform = transforms.Compose(\n",
    "    [\n",
    "        input_resize,\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(imagenet_mean, imagenet_std),\n",
    "    ]\n",
    ")\n",
    "\n",
    "target_resize = transforms.Resize((224, 224), interpolation=InterpolationMode.NEAREST)\n",
    "target_transform = transforms.Compose(\n",
    "    [\n",
    "        target_resize,\n",
    "        transforms.PILToTensor(),\n",
    "        transforms.Lambda(lambda x: replace_tensor_value_(x.squeeze(0).long(), 255, 21)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Creating the dataset\n",
    "train_dataset = datasets.VOCSegmentation(\n",
    "    './datasets/',\n",
    "    year='2007',\n",
    "    download=True,\n",
    "    image_set='train',\n",
    "    transform=input_transform,\n",
    "    target_transform=target_transform,\n",
    ")\n",
    "valid_dataset = datasets.VOCSegmentation(\n",
    "    './datasets/',\n",
    "    year='2007',\n",
    "    download=True,\n",
    "    image_set='val',\n",
    "    transform=input_transform,\n",
    "    target_transform=target_transform,\n",
    ")\n",
    "test_dataset = datasets.VOCSegmentation(\n",
    "    './data/VOC/',\n",
    "    year='2007',\n",
    "    download=True,\n",
    "    image_set='test',\n",
    "    transform=input_transform,\n",
    "    target_transform=target_transform,\n",
    ")\n",
    "\n",
    "# Creating the dataloader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df3767b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a VOC dataset without normalization for visualization.\n",
    "train_dataset_viz = datasets.VOCSegmentation(\n",
    "    './datasets/',\n",
    "    year='2007',\n",
    "    image_set='train',\n",
    "    transform=input_resize,\n",
    "    target_transform=target_resize,\n",
    ")\n",
    "inputs, ground_truths = map(list, zip(*[train_dataset_viz[i] for i in range(batch_size)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de0d3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_images(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec1df31",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_images(ground_truths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806bb1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifying loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# specifying the network\n",
    "from monet import MoNet\n",
    "network = MoNet(in_channels = 3, out_channels = 22)\n",
    "# network = smp.Unet('resnet34', encoder_weights='imagenet', classes=22)\n",
    "\n",
    "# specifying optimizer\n",
    "optimizer = optim.Adam(network.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c50a1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19eb07fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks\n",
    "save_path = 'saves/unet-voc'\n",
    "\n",
    "# Creating saving directory\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "callbacks = [\n",
    "    # Save the latest weights to be able to continue the optimization at the end for more epochs.\n",
    "    ModelCheckpoint(os.path.join(save_path, 'last_weights.ckpt')),\n",
    "    # Save the weights in a new file when the current model is better than all previous models.\n",
    "    ModelCheckpoint(\n",
    "        os.path.join(save_path, 'best_weight.ckpt'),\n",
    "        save_best_only=True,\n",
    "        restore_best=True,\n",
    "        verbose=True,\n",
    "    ),\n",
    "    # Save the losses for each epoch in a TSV.\n",
    "    CSVLogger(os.path.join(save_path, 'log.tsv'), separator='\\t'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ce3a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poutyne Model on GPU\n",
    "model = Model(\n",
    "    network,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    batch_metrics=['accuracy'],\n",
    "    epoch_metrics=['f1', torchmetrics.JaccardIndex(num_classes=22)],\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "# Train\n",
    "_ = model.fit_generator(train_loader, valid_loader, epochs=30, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaa24b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, (acc, f1, jaccard) = model.evaluate_generator(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538d5074",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, ground_truths = next(iter(test_loader))\n",
    "outputs = model.predict_on_batch(inputs)\n",
    "outputs = outputs.argmax(1)\n",
    "\n",
    "outputs = replace_tensor_value_(outputs, 21, 255)\n",
    "ground_truths = replace_tensor_value_(ground_truths, 21, 255)\n",
    "\n",
    "plt_inputs = np.clip(inputs.numpy().transpose((0, 2, 3, 1)) * imagenet_std + imagenet_mean, 0, 1)\n",
    "fig = plot_images(plt_inputs)\n",
    "fig.suptitle(\"Images\")\n",
    "\n",
    "pil_outputs = [array1d_to_pil_image(out) for out in outputs]\n",
    "fig = plot_images(pil_outputs)\n",
    "fig.suptitle(\"Predictions\")\n",
    "\n",
    "pil_ground_truths = [array1d_to_pil_image(gt) for gt in ground_truths.numpy()]\n",
    "fig = plot_images(pil_ground_truths)\n",
    "_ = fig.suptitle(\"Ground truths\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
