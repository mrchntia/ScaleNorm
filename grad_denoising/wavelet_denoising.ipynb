{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77709756",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepee import (PrivacyWrapper, PrivacyWatchdog, UniformDataLoader,\n",
    "                     ModelSurgeon, SurgicalProcedures)\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import functional as F\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "from skimage.restoration import denoise_wavelet\n",
    "\n",
    "batch_size = 200\n",
    "test_batch_size = 200\n",
    "log_interval = 1000\n",
    "epochs = 5\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61781be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = UniformDataLoader(\n",
    "    \n",
    "    datasets.MNIST(\n",
    "        \"../data\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.1307,), (0.3081,)),\n",
    "            ]\n",
    "        ),\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        \"../data\",\n",
    "        train=False,\n",
    "        transform=transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.1307,), (0.3081,)),\n",
    "            ]\n",
    "        ),\n",
    "    ),\n",
    "    batch_size=test_batch_size,\n",
    "    shuffle=True,\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1195268",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.bn1 = nn.BatchNorm1d(256, track_running_stats=False)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        x = self.bn1(x)\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b71d1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wavelet_denoiser(model, sigma):\n",
    "    model.wrapped_model.fc1.weight.grad = torch.tensor(\n",
    "        denoise_wavelet(np.array(model.wrapped_model.fc1.weight.grad), sigma, rescale_sigma=True)\n",
    "    )\n",
    "    model.wrapped_model.fc2.weight.grad = torch.tensor(\n",
    "        denoise_wavelet(np.array(model.wrapped_model.fc2.weight.grad), sigma, rescale_sigma=True)\n",
    "    )\n",
    "    model.wrapped_model.fc3.weight.grad = torch.tensor(\n",
    "        denoise_wavelet(np.array(model.wrapped_model.fc3.weight.grad), sigma, rescale_sigma=True)\n",
    "    )\n",
    "       \n",
    "def wavelet_denoiser_flatten(model, sigma, mode):\n",
    "    size_fc1 = model.wrapped_model.fc1.weight.grad.size()\n",
    "    model.wrapped_model.fc1.weight.grad = torch.tensor(\n",
    "        denoise_wavelet(\n",
    "            np.array(\n",
    "                torch.flatten(\n",
    "                    model.wrapped_model.fc1.weight.grad\n",
    "                )\n",
    "            ),\n",
    "            sigma,\n",
    "            rescale_sigma=True,\n",
    "            method = \"VisuShrink\"\n",
    "        )\n",
    "    ).unflatten(0, size_fc1)\n",
    "    \n",
    "    size_fc2 = model.wrapped_model.fc2.weight.grad.size()\n",
    "    model.wrapped_model.fc2.weight.grad = torch.tensor(\n",
    "        denoise_wavelet(\n",
    "            np.array(\n",
    "                torch.flatten(\n",
    "                    model.wrapped_model.fc2.weight.grad\n",
    "                )\n",
    "            ),\n",
    "            sigma,\n",
    "            rescale_sigma=True,\n",
    "            method = \"VisuShrink\"\n",
    "        )\n",
    "    ).unflatten(0, size_fc2)\n",
    "    \n",
    "    size_fc3 = model.wrapped_model.fc3.weight.grad.size()\n",
    "    model.wrapped_model.fc3.weight.grad = torch.tensor(\n",
    "        denoise_wavelet(\n",
    "            np.array(\n",
    "                torch.flatten(\n",
    "                    model.wrapped_model.fc3.weight.grad\n",
    "                )\n",
    "            ),\n",
    "            sigma,\n",
    "            rescale_sigma=True,\n",
    "            method = \"VisuShrink\"\n",
    "        )\n",
    "    ).unflatten(0, size_fc3)\n",
    "        \n",
    "def plot_grad_hist(model, layer, rows, columns, i, title=\"Gradient histogram\", y_lim=7500):\n",
    "    bins = 50\n",
    "    x_range = (-0.02, 0.02)\n",
    "    \n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    if layer == 1:\n",
    "        plt.hist(\n",
    "            np.transpose(np.array(torch.flatten(model.fc1.weight.grad))), \n",
    "            bins=bins, \n",
    "            range=x_range\n",
    "        )\n",
    "    elif layer == 2:\n",
    "        plt.hist(\n",
    "            np.transpose(np.array(torch.flatten(model.fc2.weight.grad))), \n",
    "            bins=bins, \n",
    "            range=x_range\n",
    "        )\n",
    "    elif layer == 3:\n",
    "        plt.hist(\n",
    "            np.transpose(np.array(torch.flatten(model.fc3.weight.grad))), \n",
    "            bins=bins, \n",
    "            range=x_range\n",
    "        )\n",
    "    plt.title(title)\n",
    "    plt.ylim(0, y_lim)\n",
    "    \n",
    "def plot_grad_image(model, layer, rows, columns, i, title=\"Gradient image\"):\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    if layer == 1:\n",
    "        plt.imshow(F.to_pil_image(model.fc1.weight.grad))\n",
    "    elif layer == 2:\n",
    "        plt.imshow(F.to_pil_image(model.fc2.weight.grad))\n",
    "    elif layer == 3:\n",
    "        plt.imshow(F.to_pil_image(model.fc3.weight.grad))\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d7161c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/helena/.virtualenvs/thesis/lib/python3.9/site-packages/torch/autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.285782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Privacy spent at 100 steps: 0.18\n",
      "INFO:root:Privacy spent at 200 steps: 0.27\n",
      "INFO:root:Privacy spent at 300 steps: 0.34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.6390, Accuracy: 8337/10000 (83%)\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.688148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Privacy spent at 400 steps: 0.39\n",
      "INFO:root:Privacy spent at 500 steps: 0.44\n",
      "INFO:root:Privacy spent at 600 steps: 0.49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.4098, Accuracy: 8975/10000 (90%)\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.565715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Privacy spent at 700 steps: 0.53\n",
      "INFO:root:Privacy spent at 800 steps: 0.57\n",
      "INFO:root:Privacy spent at 900 steps: 0.61\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.3666, Accuracy: 9138/10000 (91%)\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.555389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Privacy spent at 1000 steps: 0.65\n",
      "INFO:root:Privacy spent at 1100 steps: 0.68\n",
      "INFO:root:Privacy spent at 1200 steps: 0.72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.3085, Accuracy: 9251/10000 (93%)\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.323882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Privacy spent at 1300 steps: 0.75\n",
      "INFO:root:Privacy spent at 1400 steps: 0.78\n"
     ]
    }
   ],
   "source": [
    "watchdog = PrivacyWatchdog(\n",
    "    train_loader,\n",
    "    target_epsilon=1.0,\n",
    "    abort=False,\n",
    "    target_delta=1e-5,\n",
    "    fallback_to_rdp=False,\n",
    ")\n",
    "model = PrivacyWrapper(SimpleNet(), batch_size, 1.0, 1.0, watchdog=watchdog).to(\n",
    "    device\n",
    ")\n",
    "optimizer = torch.optim.SGD(model.wrapped_model.parameters(), lr=0.1)\n",
    "\n",
    "surgeon = ModelSurgeon(SurgicalProcedures.BN_to_GN)\n",
    "model = surgeon.operate(model)\n",
    "\n",
    "sigma = 0.002\n",
    "plot_layer = 2\n",
    "y_lim = 8000\n",
    "rows = 6\n",
    "columns = 3\n",
    "i = 1\n",
    "fig = plt.figure(figsize=(columns*7, rows*4))\n",
    "\n",
    "# Train\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = torch.nn.CrossEntropyLoss()(output, target)\n",
    "        loss.backward()\n",
    "        \n",
    "        if epoch == 4 and (batch_idx == 50 or batch_idx == 100 or batch_idx == 150):\n",
    "            grad = torch.flatten(model.wrapped_model.fc2.weight.grad).detach().clone()\n",
    "            \n",
    "            model.clip_and_accumulate()\n",
    "            \n",
    "            clipped_grad = torch.flatten(model.wrapped_model.fc2.weight.grad).detach().clone()\n",
    "            num_grad = len(clipped_grad)\n",
    "            \n",
    "            title = \"Clipped (Epoch: {}, Batch: {})\".format(epoch, batch_idx)\n",
    "            plot_grad_hist(model.wrapped_model, plot_layer, rows, columns, i, title, y_lim)\n",
    "            plot_grad_image(model.wrapped_model, plot_layer, rows, columns, i+3, title)\n",
    "\n",
    "            model.noise_gradient()\n",
    "\n",
    "            l2_clipped = sum(abs(clipped_grad**2 - torch.flatten(model.wrapped_model.fc2.weight.grad)**2)**(1/2))\n",
    "            l2 = sum(abs(grad**2 - torch.flatten(model.wrapped_model.fc2.weight.grad)**2)**(1/2))\n",
    "            title = \"Noisy (Epoch: {}, Batch: {}, L2 clipped: {:.0f}, L2: {:.0f})\".format(epoch, batch_idx, l2_clipped, l2)\n",
    "            plot_grad_hist(model.wrapped_model, plot_layer, rows, columns, i+1, title, y_lim)\n",
    "            plot_grad_image(model.wrapped_model, plot_layer, rows, columns, i+4, title)\n",
    "            \n",
    "            wavelet_denoiser(model, sigma)\n",
    "            \n",
    "            l2_clipped = sum(abs(clipped_grad**2 - torch.flatten(model.wrapped_model.fc2.weight.grad)**2)**(1/2))\n",
    "            l2 = sum(abs(grad**2 - torch.flatten(model.wrapped_model.fc2.weight.grad)**2)**(1/2))\n",
    "            title = \"Wavelet (Epoch: {}, Batch: {}, L2 clipped: {:.0f}, L2: {:.0f})\".format(epoch, batch_idx, l2_clipped, l2)\n",
    "            plot_grad_hist(model.wrapped_model, plot_layer, rows, columns, i+2, title, y_lim)\n",
    "            plot_grad_image(model.wrapped_model, plot_layer, rows, columns, i+5, title)\n",
    "            \n",
    "            i = i+6\n",
    "        else:\n",
    "            model.clip_and_accumulate()\n",
    "            model.noise_gradient()\n",
    "            wavelet_denoiser(model, sigma)\n",
    "\n",
    "        optimizer.step()\n",
    "        model.prepare_next_batch()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(\n",
    "                \"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                    epoch,\n",
    "                    batch_idx * len(data),\n",
    "                    len(train_loader.dataset),\n",
    "                    100.0 * batch_idx / len(train_loader),\n",
    "                    loss.item(),\n",
    "                )\n",
    "            )\n",
    "\n",
    "    # Test\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += torch.nn.CrossEntropyLoss(reduction=\"sum\")(\n",
    "                output, target\n",
    "            ).item()  # sum up batch loss\n",
    "            pred = output.argmax(\n",
    "                dim=1, keepdim=True\n",
    "            )  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print(\n",
    "        \"\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\".format(\n",
    "            test_loss,\n",
    "            correct,\n",
    "            len(test_loader.dataset),\n",
    "            100.0 * correct / len(test_loader.dataset),\n",
    "        )\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
